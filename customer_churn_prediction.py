# -*- coding: utf-8 -*-
"""customer churn prediction

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1yxaIVFd1shWqVqKYmj_eH4HEUcOiihGz
"""

# Commented out IPython magic to ensure Python compatibility.
from google.colab import drive
drive.mount('/gdrive/')
# %cd /gdrive

ls

cd /gdrive/MyDrive/Customer churn prediction

ls

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.utils import resample
from sklearn.preprocessing import LabelEncoder
from sklearn.experimental import enable_iterative_imputer
from sklearn.impute import IterativeImputer
from sklearn import preprocessing
from sklearn.feature_selection import SelectKBest, chi2
from sklearn.feature_selection import SelectFromModel
from sklearn.ensemble import RandomForestClassifier as rf
import warnings

df=pd.read_csv('customer_churn.csv')
df.head()

df.info()

df.columns

df.Churn.value_counts()

columns = df.columns
binary_cols = []

for col in columns:
    if df[col].value_counts().shape[0] == 2:
        binary_cols.append(col)

binary_cols

multiple_cols = ['MultipleLines', 'InternetService', 'OnlineSecurity', 'OnlineBackup',
 'DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies', 'Contract','PaymentMethod']

fig, axes = plt.subplots(2, 3, figsize=(12, 7), sharey=True)

sns.countplot("gender", data=df, ax=axes[0,0])
sns.countplot("SeniorCitizen", data=df, ax=axes[0,1])
sns.countplot("Partner", data=df, ax=axes[0,2])
sns.countplot("Dependents", data=df, ax=axes[1,0])
sns.countplot("PhoneService", data=df, ax=axes[1,1])
sns.countplot("PaperlessBilling", data=df, ax=axes[1,2])

churn_numeric = {'Yes':1, 'No':0}
df.Churn.replace(churn_numeric, inplace=True)

df[['gender','Churn']].groupby(['gender']).mean()

sns.countplot("InternetService", data=df)

fig, axes = plt.subplots(2, 3, figsize=(12, 7), sharey=True)

sns.countplot("StreamingTV", data=df, ax=axes[0,0])
sns.countplot("StreamingMovies", data=df, ax=axes[0,1])
sns.countplot("OnlineSecurity", data=df, ax=axes[0,2])
sns.countplot("OnlineBackup", data=df, ax=axes[1,0])
sns.countplot("DeviceProtection", data=df, ax=axes[1,1])
sns.countplot("TechSupport", data=df, ax=axes[1,2])

sns.distplot(df["MonthlyCharges"])

df.drop(['customerID','gender','PhoneService','Contract','TotalCharges'], axis=1, inplace=True)

from sklearn.preprocessing import LabelEncoder, OneHotEncoder
from sklearn.preprocessing import MinMaxScaler

cat_features = ['SeniorCitizen', 'Partner', 'Dependents',
        'MultipleLines', 'InternetService', 'OnlineSecurity',
       'OnlineBackup', 'DeviceProtection', 'TechSupport', 'StreamingTV',
       'StreamingMovies', 'PaperlessBilling', 'PaymentMethod']
X = pd.get_dummies(df, columns=cat_features, drop_first=True)

sc = MinMaxScaler()
a = sc.fit_transform(df[['tenure']])
b = sc.fit_transform(df[['MonthlyCharges']])

X['tenure'] = a
X['MonthlyCharges'] = b

X_no = X[X.Churn == 0]
X_yes = X[X.Churn == 1]

print(len(X_no),len(X_yes))

X_yes_upsampled = X_yes.sample(n=len(X_no), replace=True, random_state=42)
print(len(X_yes_upsampled))

X_upsampled = X_no.append(X_yes_upsampled).reset_index(drop=True)
sns.countplot('Churn', data=X_upsampled).set_title('Class Distribution After Resampling')

from sklearn.model_selection import train_test_split
X = X_upsampled.drop(['Churn'], axis=1) 
y = X_upsampled['Churn']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=42)

"""# Ridge Classifier"""

from sklearn.linear_model import RidgeClassifier
from sklearn.metrics import accuracy_score
from sklearn.metrics import confusion_matrix

clf_ridge = RidgeClassifier()
clf_ridge.fit(X_train, y_train)

pred = clf_ridge.predict(X_train) 
accuracy_score(y_train, pred)

confusion_matrix(y_train, pred)

pred_test = clf_ridge.predict(X_test)
q=accuracy_score(y_test, pred_test)

from sklearn.metrics import precision_score, recall_score, confusion_matrix, classification_report, accuracy_score, f1_score

print(classification_report(y_test, pred_test))

cma = confusion_matrix(y_test, pred_test)

fig, ax = plt.subplots(figsize=(5, 5))
ax.matshow(cma, cmap=plt.cm.Blues, alpha=0.3)
for i in range(cma.shape[0]):
    for j in range(cma.shape[1]):
        ax.text(x=j, y=i,s=cma[i, j], va='center', ha='center', size='xx-large')
 
plt.xlabel('Predictions', fontsize=18)
plt.ylabel('Actuals', fontsize=18)
plt.title('Confusion Matrix', fontsize=18)
plt.show()

"""# Decision tree classifier"""

from sklearn import tree

clf = tree.DecisionTreeClassifier()
 clf = clf.fit(X_train, y_train)

pred1 = clf.predict(X_train)
accuracy_score(y_train, pred1)

confusion_matrix(y_train, pred1)

pred1_test = clf.predict(X_test)
r=accuracy_score(y_test, pred1_test)

print(classification_report(y_test, pred1_test))

cma = confusion_matrix(y_test, pred1_test)

fig, ax = plt.subplots(figsize=(5, 5))
ax.matshow(cma, cmap ="coolwarm_r", alpha=0.3)
for i in range(cma.shape[0]):
    for j in range(cma.shape[1]):
        ax.text(x=j, y=i,s=cma[i, j], va='center', ha='center', size='xx-large')
 
plt.xlabel('Predictions', fontsize=18)
plt.ylabel('Actuals', fontsize=18)
plt.title('Confusion Matrix', fontsize=18)
plt.show()

"""# Logistic regression"""

from sklearn.linear_model import LogisticRegression  
clf= LogisticRegression(random_state=0)  
clf.fit(X_train, y_train)

pred_LR= clf.predict(X_train)
accuracy_score(y_train, pred_LR)

confusion_matrix(y_train, pred_LR)

pred_LR_test = clf.predict(X_test)
s=accuracy_score(y_test, pred_LR_test)

print(classification_report(y_test, pred_LR_test))

cma = confusion_matrix(y_test, pred_LR_test)

fig, ax = plt.subplots(figsize=(5, 5))
ax.matshow(cma, cmap ="coolwarm_r", alpha=0.3)
for i in range(cma.shape[0]):
    for j in range(cma.shape[1]):
        ax.text(x=j, y=i,s=cma[i, j], va='center', ha='center', size='xx-large')
 
plt.xlabel('Predictions', fontsize=18)
plt.ylabel('Actuals', fontsize=18)
plt.title('Confusion Matrix', fontsize=18)
plt.show()

"""# Support vector machine"""

from sklearn.svm import SVC  
classifier = SVC(kernel='linear', random_state=0)  
classifier.fit(X_train, y_train)

pred_SVM= classifier.predict(X_train)
accuracy_score(y_train, pred_SVM)

confusion_matrix(y_train, pred_SVM)

pred_SVM_test = classifier.predict(X_test)
t=accuracy_score(y_test, pred_SVM_test)

print(classification_report(y_test, pred_SVM_test))

cma = confusion_matrix(y_test, pred_SVM_test)

fig, ax = plt.subplots(figsize=(5, 5))
ax.matshow(cma, cmap ="prism", alpha=0.3)
for i in range(cma.shape[0]):
    for j in range(cma.shape[1]):
        ax.text(x=j, y=i,s=cma[i, j], va='center', ha='center', size='xx-large')
 
plt.xlabel('Predictions', fontsize=18)
plt.ylabel('Actuals', fontsize=18)
plt.title('Confusion Matrix', fontsize=18)
plt.show()

"""# Neural networks"""

from sklearn.neural_network import MLPClassifier

clf= MLPClassifier(solver='lbfgs', alpha=1e-5,
           hidden_layer_sizes=(5, 2), random_state=1)
clf.fit(X_train, y_train)

pred_NN= clf.predict(X_train)
accuracy_score(y_train, pred_NN)

confusion_matrix(y_train, pred_SVM)

pred_NN_test = clf.predict(X_test)
u=accuracy_score(y_test, pred_NN_test)

print(classification_report(y_test, pred_NN_test))

cma = confusion_matrix(y_test, pred_NN_test)

fig, ax = plt.subplots(figsize=(5, 5))
ax.matshow(cma, cmap ="prism", alpha=0.3)
for i in range(cma.shape[0]):
    for j in range(cma.shape[1]):
        ax.text(x=j, y=i,s=cma[i, j], va='center', ha='center', size='xx-large')
 
plt.xlabel('Predictions', fontsize=18)
plt.ylabel('Actuals', fontsize=18)
plt.title('Confusion Matrix', fontsize=18)
plt.show()

"""# Random forest cassifier"""

clf_forest = rf(n_estimators=100, max_depth=10)
clf_forest.fit(X_train, y_train)

pred = clf_forest.predict(X_train)
accuracy_score(y_train, pred)

confusion_matrix(y_train, pred)

pred_test = clf_forest.predict(X_test)
v=accuracy_score(y_test, pred_test)

from sklearn.model_selection import GridSearchCV

parameters = {'n_estimators':[150,200,250,300], 'max_depth':[15,20,25]}
forest =rf()
clf = GridSearchCV(estimator=forest, param_grid=parameters, n_jobs=-1, cv=5)

clf.fit(X, y)

clf.best_params_

clf.best_score_

print(classification_report(y_test, pred_test))

cma = confusion_matrix(y_test, pred_test)

fig, ax = plt.subplots(figsize=(5, 5))
ax.matshow(cma, cmap=plt.cm.Oranges, alpha=0.3)
for i in range(cma.shape[0]):
    for j in range(cma.shape[1]):
        ax.text(x=j, y=i,s=cma[i, j], va='center', ha='center', size='xx-large')
 
plt.xlabel('Predictions', fontsize=18)
plt.ylabel('Actuals', fontsize=18)
plt.title('Confusion Matrix', fontsize=18)
plt.show()

"""# Comparative Analysis"""

import numpy as np
import matplotlib.pyplot as plt
# creating the dataset
data = {'RC':q, 'DT':r,'LR':s,'SVM':t,'NN':u, 'RF':v}
courses = list(data.keys())
values = list(data.values())
fig = plt.figure(figsize = (10, 5))
# creating the bar plot
plt.bar(courses, values, color ='maroon',
		width = 0.4)
plt.xlabel("Algorithms")
plt.ylabel("Accuracy")
plt.title("Compaaritive analysis of algorithm on the basis of the acccuracy")
plt.show()

activities = ['RC', 'DT', 'LR','SVM','NN', 'RF'] 
# portion covered by each label
slices = [q,r,s,t,u,v]
 
# color for each label
colors = ['red', 'blue','pink','green','yellow','purple']
 
# plotting the pie chart
plt.pie(slices, labels = activities, colors=colors,
        startangle=90, shadow = True, explode = (0, 0, 0.1,0,0,0.1),
        radius = 1.5, autopct = '%1.1f%%')
 
# plotting legend
plt.legend()
 
# showing the plot
plt.show()